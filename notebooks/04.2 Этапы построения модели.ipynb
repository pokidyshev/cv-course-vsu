{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этапы построения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Структура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев ваша нейронная сеть -- _последовательность_ слоев. То есть они идут последовательно друг за другом, и выход каждого  слоя является входом к следующему.\n",
    "\n",
    "Для описания подобного рода моделей в keras есть удобная модель: __Sequential__. Она автоматически соединяет слои правильно, как и описано выше.\n",
    "\n",
    "Для большинства случаев на практике такой нам и будет достаточно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(),\n",
    "    Activation(),\n",
    "    Dropout(),\n",
    "    Dense(),\n",
    "    # ...\n",
    "    Dense()\n",
    "    \n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать каждый слой отдельно от всех других, то у него, конечно, есть свой вход и свой выход. Keras functional API, или, говоря по-русски, функциональный стиль описания моделей keras, позволяет нам описывать слои по отдельности и соединять в любом порядке, соединять несколько выходов и один и все такое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input()           # вход\n",
    "dense1 = Dense()(input_layer)   # полносвязный слой подсоединяем к входу\n",
    "dense2 = Dense()(dense1)        # следующий полносвязный - к предыдущему\n",
    "output_layer = Dense()(dense2)  # выходной слой\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| __Как называется по-русски__ | __Как называется по-пацански__ | __Как называется в мире keras__ | __Что делает__ |\n",
    "|:--------------------:|:------------------------:|:----------------------:|\n",
    "| Полносвязный | Дэнс | __Dense__ | $\\sigma(\\omega x + b)$ - то есть предоставляет и хранит матрицу весов $\\omega$ и вектор смещений $b$, являющимися обучаемыми параметрами. Опционально может сразу применить функцию активации $\\sigma$ от результата _(обычно так и делают)_.|\n",
    "| Активация       | Активэйшн    |       __Activation__              | Только функция активации $\\sigma$. |\n",
    "| Нормализация батча | Батчнорм | __BatchNormalization__ | Модифицирует выходные значения очередного слоя так, чтобы среднее значение активаций было равным 0 и среднеквадратичное отклонение было равным 1 |\n",
    "| Исключение | Дропаут | __Dropout__ | Случайным образом выкидывает некоторое количество весов, чтобы нейросеть училась формировать предсказания на том, что осталось. Таким образом она будет учиться лучше генерализовать и меньше запоминать выборку, словом, является регуляризатором. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Функция потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ MSE = \\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ MAE = \\frac{1}{N}\\sum_{i=1}^{N} |y_i - \\hat{y}_i| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__У вас в данных есть выбросы?__ $\\rightarrow$ Используй __MAE__!\n",
    "\n",
    "__Уверен, что они выбросы?__ $\\rightarrow$ Используй __MAE__!\n",
    "\n",
    "__\"Выбросы\" - нормальные значения, которые могут появляться?__ $\\rightarrow$ Используй __MSE__!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Бинарная кросс-энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ BinaryCrossEntropy = −(y\\log(\\hat{y}) + (1 − y)\\log(1 − \\hat{y})) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Категориальная кросс-энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ CategoricalCrossEntropy = −\\sum_{c=1}^{M} y_{o,c}\\log(p_{o, c}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $M=2$ вырождается в бинарную, очевидно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрику очень важно не путать с функцией потерь!\n",
    "\n",
    "__Метрика__ нужна для _человека_, чтобы измерить качество модели в понятной ему величине. __Функция потерь__ нужна для _алгоритма_, чтобы правильно ползать по поверхности функции стоимости и находить лучшее решение. \n",
    "\n",
    "Эти две величины __не обязательно__ напрямую связаны! Достижение лучшего решение по функции стоимости не означает, что в результате вы получите самую точную модель.\n",
    "\n",
    "_P.s. Но в целом в большинстве случаев так и происходит. Кроме того, в случае регрессии, например, обычно метрики и функции потерь совпадают, скажем, везде берут MSE._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Для задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. MSE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно так же, как и выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы предсказываем сумму продаж в рублях. Тогда MSE даст нам.. квадрат рублей? Не очень удобно. То ли дело взять из значения ошибки корень, то есть вычислить __RMSE__ - Root Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "model.compile(metrics=[rmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля правильно угаданных экземляров выборки, ничего особенного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Почитать на дом\n",
    "\n",
    "https://habr.com/company/ods/blog/328372/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
